{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install and Import Required Packages"
      ],
      "metadata": {
        "id": "s8bfyfIZmW-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-RL-weywWT-"
      },
      "outputs": [],
      "source": [
        "!pip install xmltodict\n",
        "!pip install split-folders\n",
        "!pip install easyocr\n",
        "!pip install GPUtil\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "!cd yolov5 && pip install -r requirements.txt comet_ml  # install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI1kRmMpvD5D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import uuid\n",
        "import time\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "import xmltodict\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import random as rnd\n",
        "import splitfolders\n",
        "import easyocr\n",
        "import PIL\n",
        "import copy\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import torch\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('TkAgg')\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image as mpimg\n",
        "from matplotlib import patches as mpatches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import comet_ml\n",
        "import torch"
      ],
      "metadata": {
        "id": "3S5qq7OrVwqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjHgeSr9vD5D"
      },
      "source": [
        "# 2. Import a Dataset for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjGGFGsKvD5E"
      },
      "source": [
        "### Use only one of the follow datasets. I decided on option C for the best balance of training time, and accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option A - 433 images (Requires Formating for use with Yolov5)"
      ],
      "metadata": {
        "id": "hEe8sEoYoBq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Souce: https://www.kaggle.com/datasets/andrewmvd/car-plate-detection I added this to my Google Drive to quickly import in new session. Modify the following code snippet based on how you import the data"
      ],
      "metadata": {
        "id": "8COb94mroRqQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIKxSj7_WKEb"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp -r drive/MyDrive/FYP/PlateRecognition .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define dictionary with the basic informations about the dataset."
      ],
      "metadata": {
        "id": "k-UVEgxPoJlF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp16LIwwvD5E"
      },
      "outputs": [],
      "source": [
        "dataset = {\n",
        "            \"file\":[],\n",
        "            \"width\":[],\n",
        "            \"height\":[],\n",
        "            \"xmin\":[],\n",
        "            \"ymin\":[],\n",
        "            \"xmax\":[],\n",
        "            \"ymax\":[]\n",
        "           }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjMlQsEAvD5F"
      },
      "outputs": [],
      "source": [
        "img_names=[] \n",
        "annotations=[]\n",
        "for dirname, _, filenames in os.walk(\"PlateRecognition\"):\n",
        "    for filename in filenames:\n",
        "        if os.path.join(dirname, filename)[-3:]==(\"png\" or \"jpg\"):\n",
        "            img_names.append(filename)\n",
        "        elif os.path.join(dirname, filename)[-3:]==\"xml\":\n",
        "            annotations.append(filename)\n",
        "    \n",
        "img_names[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aexkd4xhvD5F"
      },
      "outputs": [],
      "source": [
        "annotations[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o3MHXGovD5F"
      },
      "source": [
        "Rewrite the info from .xml to the dictionary. For each photo we can get multiple bonding boxes, therefore filenames, width and height will recur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTaQbcA-vD5F"
      },
      "outputs": [],
      "source": [
        "path_annotations=\"PlateRecognition/annotations/*.xml\" \n",
        "\n",
        "for item in glob.glob(path_annotations):\n",
        "    tree = ET.parse(item)\n",
        "    \n",
        "    for elem in tree.iter():\n",
        "        if 'filename' in elem.tag:\n",
        "            filename=elem.text\n",
        "        elif 'width' in elem.tag:\n",
        "            width=int(elem.text)\n",
        "        elif 'height' in elem.tag:\n",
        "            height=int(elem.text)\n",
        "        elif 'xmin' in elem.tag:\n",
        "            xmin=int(elem.text)\n",
        "        elif 'ymin' in elem.tag:\n",
        "            ymin=int(elem.text)\n",
        "        elif 'xmax' in elem.tag:\n",
        "            xmax=int(elem.text)\n",
        "        elif 'ymax' in elem.tag:\n",
        "            ymax=int(elem.text)\n",
        "            \n",
        "            dataset['file'].append(filename)\n",
        "            dataset['width'].append(width)\n",
        "            dataset['height'].append(height)\n",
        "            dataset['xmin'].append(xmin)\n",
        "            dataset['ymin'].append(ymin)\n",
        "            dataset['xmax'].append(xmax)\n",
        "            dataset['ymax'].append(ymax)\n",
        "        \n",
        "classes = ['license']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxhaT7t-vD5G"
      },
      "source": [
        "YOLO model requires normalized data (in range 0 to 1) in format [class_id, x, y, width, height], where x, y are coordinates of the middle of the bounding box(with corresponding width and height). Data must be saved as a txt file with a name corresponding to an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go9ZPg1uvD5G"
      },
      "outputs": [],
      "source": [
        "x_pos = []\n",
        "y_pos = []\n",
        "frame_width = []\n",
        "frame_height = []\n",
        "\n",
        "labels_path = Path(\"PlateRecognition/labels\")\n",
        "\n",
        "labels_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "save_type = 'w'\n",
        "\n",
        "for i, row in enumerate(df.iloc):\n",
        "    current_filename = str(row.file[:-4])\n",
        "    \n",
        "    width, height, xmin, ymin, xmax, ymax = list(df.iloc[i][-6:])\n",
        "    \n",
        "    x=(xmin+xmax)/2/width\n",
        "    y=(ymin+ymax)/2/height\n",
        "    width=(xmax-xmin)/width\n",
        "    height=(ymax-ymin)/height\n",
        "    \n",
        "    x_pos.append(x)\n",
        "    y_pos.append(y)\n",
        "    frame_width.append(width)\n",
        "    frame_height.append(height)\n",
        "    \n",
        "    txt = '0' + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + '\\n'\n",
        "    \n",
        "    if i > 0:\n",
        "        previous_filename = str(df.file[i-1][:-4])\n",
        "        save_type='a+' if current_filename == previous_filename else 'w'\n",
        "    \n",
        "    \n",
        "    with open(\"PlateRecognition/labels/\" + str(row.file[:-4]) +'.txt', save_type) as f:\n",
        "        f.write(txt)\n",
        "        \n",
        "        \n",
        "df['x_pos']=x_pos\n",
        "df['y_pos']=y_pos\n",
        "df['frame_width']=frame_width\n",
        "df['frame_height']=frame_height\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6hgrlaOvD5G"
      },
      "source": [
        "Use splitfolder library to split images and labels into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCbEM5DpvD5H",
        "outputId": "f3ff92cf-5462-4af9-84da-66a6a42351e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 1309 files [00:00, 2904.65 files/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving files finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "input_folder = Path(\"PlateRecognition\")\n",
        "output_folder = Path(\"yolov5/data/PlateRecognition\")\n",
        "splitfolders.ratio(\n",
        "    input_folder,\n",
        "    output=output_folder,\n",
        "    seed=42,\n",
        "    ratio=(0.8, 0.2),\n",
        "    group_prefix=None\n",
        ")\n",
        "print(\"Moving files finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ5AiK6svD5H"
      },
      "source": [
        "Yolo requires config data in .yaml file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ4UnkVqvD5H"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "yaml_file = 'yolov5/data/plates.yaml'\n",
        "\n",
        "yaml_data = dict(\n",
        "    path = \"data/PlateRecognition\",\n",
        "    train = \"train\",\n",
        "    val = \"val\",\n",
        "    nc = len(classes),\n",
        "    names = classes\n",
        ")\n",
        "\n",
        "with open(yaml_file, 'w') as f:\n",
        "    yaml.dump(yaml_data, f, explicit_start = True, default_flow_style = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option B - 21k images"
      ],
      "metadata": {
        "id": "wxx60DGvpa6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://universe.roboflow.com/roboflow-universe-projects/license-plate-recognition-rxg4e/dataset/4 "
      ],
      "metadata": {
        "id": "cq_Qc-uww_L6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://universe.roboflow.com/ds/2JyVmpjdM5?key=ynwxbq1iAt\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "id": "z9tBLs9bOB2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option C - 7K images"
      ],
      "metadata": {
        "id": "7foe3QMMpjVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://universe.roboflow.com/roboflow-universe-projects/license-plate-recognition-rxg4e/dataset/2"
      ],
      "metadata": {
        "id": "WqncZn65UZqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://universe.roboflow.com/ds/xeLsSKTTwf?key=TDDMoeD2hz\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "id": "qYhGs0OXUlw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yejeJLVvD5H"
      },
      "source": [
        "## *(Optional)* Clear the gpu memory & check device - Training will be extremely slow on CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhIdb05jvD5H"
      },
      "outputs": [],
      "source": [
        "def free_gpu_cache() -> None:\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "free_gpu_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvOiEygJvD5I"
      },
      "outputs": [],
      "source": [
        "device = '0' if torch.cuda.is_available() else 'cpu' \n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaBF42340Ar0"
      },
      "outputs": [],
      "source": [
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TiBq7KrvD5I"
      },
      "source": [
        "# 3. Train Model\n",
        "### For model installation and required downloads check this: https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB4hpWD1mzj3"
      },
      "source": [
        "Comet API Keys for comparison of training runs (add own key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export COMET_API_KEY=\n",
        "!export COMET_PROJECT_NAME=yolov5 # This will default to 'yolov5'"
      ],
      "metadata": {
        "id": "l77_saxmjIHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model:"
      ],
      "metadata": {
        "id": "CJZW-HJSluia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDXR8z2OvD5I"
      },
      "outputs": [],
      "source": [
        "!cd yolov5 && python train.py --workers 2 --img 640 --batch 32 --epochs 100 --data \"../data.yaml\" --weights yolov5s.pt --device {device} --cache --save-period 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Iyt7B6YgkZ"
      },
      "source": [
        "Download Best Model (may need to change path to most recent run if testing different inputs in same session)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CNx8GF05Ri2m"
      },
      "outputs": [],
      "source": [
        "!zip -r platemodel.zip yolov5/runs/train/exp5\n",
        "files.download('platemodel.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iAj45jcvD5I"
      },
      "source": [
        "# 2. Test Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Rt-JBHaH-x"
      },
      "source": [
        "Import Last Best Model - (if training session was lost/left)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvb2aY8jY5oz",
        "outputId": "8f225a01-fadf-4e9f-cdfd-e8917e0b274c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "!mkdir -p yolov5/runs/train/exp/weights\n",
        "!cp drive/MyDrive/FYP/best.pt yolov5/runs/train/exp/weights/best.pt\n",
        "# !cp drive/MyDrive/FYP/PlateTestVideo.mp4 ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark Model"
      ],
      "metadata": {
        "id": "6N8Hd0hAjSJg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUM1cAjI6F5l"
      },
      "outputs": [],
      "source": [
        "!cd yolov5 && python benchmarks.py --weights runs/train/exp/weights/best.pt --imgsz 640 --device 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on Photo\n"
      ],
      "metadata": {
        "id": "I1Y6AIQxjj81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A photo must first uploaded in Colab, then change \"test_phto_path\" to match its path"
      ],
      "metadata": {
        "id": "rty2a3r-nDLn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCumWZT3vD5J",
        "outputId": "e103df5a-2b20-4055-ba67-b35df46f3200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Photo width,height: 400,262. Detected plates: 3\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "test_photo_path = \"Cars89.png\"\n",
        "\n",
        "results = model(test_photo_path)\n",
        "detections=np.squeeze(results.render())\n",
        "\n",
        "labels, coordinates = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]\n",
        "image = cv2.imread(test_photo_path)\n",
        "width, height = image.shape[1], image.shape[0]\n",
        "\n",
        "print(f'Photo width,height: {width},{height}. Detected plates: {len(labels)}')\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    row = coordinates[i]\n",
        "    if row[4] >= 0.6:\n",
        "        x1, y1, x2, y2 = int(row[0]*width), int(row[1]*height), int(row[2]*width), int(row[3]*height)\n",
        "        plate_crop = image[int(y1):int(y2), int(x1):int(x2)]\n",
        "        ocr_result = reader.readtext((plate_crop), paragraph=\"True\", min_size=120, allowlist = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "        # text=ocr_result[0][1]\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 6) ## BBox\n",
        "        # cv2.putText(image, f\"{text}\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3)\n",
        "        plt.axis(False)\n",
        "        plt.imshow((image)[...,::-1])\n",
        "        \n",
        "        print(f'Detection: {i+1}. YOLOv5 prob: {row[4]:.2f}, easyOCR results: {ocr_result}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}